# ğŸ¯ **SUITE COMPLÃˆTE DE TESTS BDD POUR VOTRE PROJET WAX NG**

Je vais vous fournir une suite de tests exhaustive couvrant tous les aspects de votre pipeline.

---

## ğŸ“ **STRUCTURE COMPLÃˆTE DU PROJET**

```
waxng/
â”œâ”€â”€ features/                              # Tests BDD
â”‚   â”œâ”€â”€ unit/                              # Tests unitaires (sans Spark)
â”‚   â”‚   â”œâ”€â”€ file_validation.feature
â”‚   â”‚   â”œâ”€â”€ config_parsing.feature
â”‚   â”‚   â”œâ”€â”€ tolerance_calculation.feature
â”‚   â”‚   â””â”€â”€ date_parsing.feature
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                       # Tests d'intÃ©gration (avec Databricks)
â”‚   â”‚   â”œâ”€â”€ unzip.feature
â”‚   â”‚   â”œâ”€â”€ autoloader.feature
â”‚   â”‚   â”œâ”€â”€ delta_operations.feature
â”‚   â”‚   â”œâ”€â”€ column_processing.feature
â”‚   â”‚   â””â”€â”€ data_quality.feature
â”‚   â”‚
â”‚   â”œâ”€â”€ e2e/                              # Tests bout-en-bout
â”‚   â”‚   â”œâ”€â”€ full_pipeline.feature
â”‚   â”‚   â”œâ”€â”€ orchestrator.feature
â”‚   â”‚   â””â”€â”€ baseline_validation.feature
â”‚   â”‚
â”‚   â””â”€â”€ steps/                            # ImplÃ©mentations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ environment.py
â”‚       â”œâ”€â”€ unit_steps.py
â”‚       â”œâ”€â”€ integration_steps.py
â”‚       â””â”€â”€ e2e_steps.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ run_unit_tests.py
â”‚   â”œâ”€â”€ run_integration_tests.py
â”‚   â””â”€â”€ run_e2e_tests.py
â”‚
â”œâ”€â”€ baseline/                             # DonnÃ©es de rÃ©fÃ©rence
â”‚   â”œâ”€â”€ site_baseline.json
â”‚   â”œâ”€â”€ activite_baseline.json
â”‚   â””â”€â”€ clymene_baseline.json
â”‚
â””â”€â”€ waxng/                                # Code source
    â””â”€â”€ ... (vos modules existants)
```

---

## ğŸ“ **TESTS UNITAIRES (SANS SPARK)**

### **1. `features/unit/file_validation.feature`**

```gherkin
# features/unit/file_validation.feature

Feature: Validation des noms de fichiers
  VÃ©rifier que les noms de fichiers respectent les conventions

  @unit @fast
  Scenario Outline: Valider diffÃ©rents formats de noms de fichiers
    Given un nom de fichier "<filename>"
    When je valide le format du nom de fichier
    Then le rÃ©sultat doit Ãªtre <valid>
    
    Examples:
      | filename                        | valid |
      | site_20251115_173355.csv       | true  |
      | activite_20251201_120000.csv   | true  |
      | site_20251115_173355.zip       | true  |
      | fichier_invalide.csv           | false |
      | site_2025_173355.csv           | false |
      | site_20251115.csv              | false |

  @unit @fast
  Scenario: Extraire la date d'un nom de fichier valide
    Given un nom de fichier "site_20251115_173355.csv"
    When j'extrais la date et l'heure
    Then la date doit Ãªtre "2025-11-15"
    And l'heure doit Ãªtre "17:33:55"

  @unit @fast
  Scenario: DÃ©tecter les extensions supportÃ©es
    Given les extensions supportÃ©es sont ".csv, .parquet, .json"
    When je vÃ©rifie le fichier "data.csv"
    Then l'extension doit Ãªtre supportÃ©e
    When je vÃ©rifie le fichier "data.xlsx"
    Then l'extension ne doit pas Ãªtre supportÃ©e
```

---

### **2. `features/unit/config_parsing.feature`**

```gherkin
# features/unit/config_parsing.feature

Feature: Parsing de la configuration
  Valider le parsing des fichiers de configuration JSON/Excel

  @unit @fast
  Scenario: Parser une configuration JSON valide
    Given un fichier de configuration JSON:
      """
      {
        "dataset": "site",
        "mode": "FULL_SNAPSHOT",
        "source_path": "/landing/",
        "target_table": "site_clymene_all",
        "expected_columns": ["SITE_CODE", "SITE_LIBELLE"]
      }
      """
    When je parse la configuration
    Then le dataset doit Ãªtre "site"
    And le mode doit Ãªtre "FULL_SNAPSHOT"
    And les colonnes attendues doivent contenir "SITE_CODE"

  @unit @fast
  Scenario: DÃ©tecter une configuration JSON invalide
    Given un fichier de configuration JSON:
      """
      {
        "dataset": "site"
        "mode": "INVALID"
      }
      """
    When je parse la configuration
    Then une erreur doit Ãªtre levÃ©e
    And le message doit contenir "JSON invalide"

  @unit @fast
  Scenario: Valider les colonnes obligatoires
    Given une configuration avec colonnes obligatoires:
      | colonne      | type   | obligatoire |
      | SITE_CODE    | STRING | true        |
      | SITE_LIBELLE | STRING | true        |
      | DATE_CREATION| DATE   | false       |
    When je valide la prÃ©sence des colonnes obligatoires
    Then "SITE_CODE" doit Ãªtre marquÃ© comme obligatoire
    And "DATE_CREATION" doit Ãªtre marquÃ© comme optionnel
```

---

### **3. `features/unit/tolerance_calculation.feature`**

```gherkin
# features/unit/tolerance_calculation.feature

Feature: Calcul des tolÃ©rances
  Calculer les tolÃ©rances pour la validation qualitÃ©

  @unit @fast
  Scenario Outline: Calculer la tolÃ©rance en pourcentage
    Given une tolÃ©rance de "<tolerance>"
    And un total de <total> lignes
    When je calcule la tolÃ©rance absolue
    Then le rÃ©sultat doit Ãªtre <expected> lignes
    
    Examples:
      | tolerance | total | expected |
      | 10%       | 1000  | 100      |
      | 5%        | 2000  | 100      |
      | 0.5%      | 10000 | 50       |
      | 100%      | 500   | 500      |

  @unit @fast
  Scenario Outline: Calculer la tolÃ©rance en valeur absolue
    Given une tolÃ©rance de "<tolerance>"
    And un total de <total> lignes
    When je calcule la tolÃ©rance absolue
    Then le rÃ©sultat doit Ãªtre <expected>
    
    Examples:
      | tolerance | total | expected |
      | 5         | 1000  | 0.005    |
      | 10        | 5000  | 0.002    |
      | 1         | 100   | 0.01     |

  @unit @fast
  Scenario: Valider une tolÃ©rance invalide
    Given une tolÃ©rance de "abc%"
    And un total de 1000 lignes
    When je calcule la tolÃ©rance absolue
    Then une erreur doit Ãªtre levÃ©e
```

---

### **4. `features/unit/date_parsing.feature`**

```gherkin
# features/unit/date_parsing.feature

Feature: Parsing des dates
  Valider le parsing de diffÃ©rents formats de dates

  @unit @fast
  Scenario Outline: Parser diffÃ©rents formats de dates
    Given une date "<date_string>" au format "<format>"
    When je parse la date
    Then la date doit Ãªtre valide
    And l'annÃ©e doit Ãªtre <year>
    And le mois doit Ãªtre <month>
    And le jour doit Ãªtre <day>
    
    Examples:
      | date_string | format     | year | month | day |
      | 2025-11-15  | YYYY-MM-DD | 2025 | 11    | 15  |
      | 15/11/2025  | DD/MM/YYYY | 2025 | 11    | 15  |
      | 20251115    | YYYYMMDD   | 2025 | 11    | 15  |

  @unit @fast
  Scenario: DÃ©tecter une date invalide
    Given une date "2025-13-45"
    When je parse la date
    Then la date doit Ãªtre invalide
    And une erreur doit Ãªtre levÃ©e
```

---

## ğŸ”§ **TESTS D'INTÃ‰GRATION (AVEC DATABRICKS)**

### **5. `features/integration/unzip.feature`**

```gherkin
# features/integration/unzip.feature

Feature: DÃ©compression de fichiers ZIP
  Tester la dÃ©compression sur Databricks

  Background:
    Given je suis sur Databricks
    And le volume est "abu_catalog.gdp_poc_dev.externalvolumetest"

  @integration @unzip
  Scenario: DÃ©compresser un fichier ZIP valide
    Given un fichier ZIP existe dans "/Volumes/.../landing/zip/site_20251115.zip"
    When je dÃ©compresse vers "/Volumes/.../preprocessed/"
    Then la dÃ©compression doit rÃ©ussir
    And au moins 1 fichier doit Ãªtre extrait
    And les fichiers extraits doivent avoir l'extension ".csv"

  @integration @unzip @negative
  Scenario: GÃ©rer un fichier ZIP corrompu
    Given un fichier ZIP corrompu existe
    When je tente de dÃ©compresser
    Then une erreur doit Ãªtre levÃ©e
    And le message doit contenir "corrupt" ou "invalid"
    And aucun fichier ne doit Ãªtre extrait

  @integration @unzip
  Scenario: Nettoyer aprÃ¨s dÃ©compression
    Given un fichier ZIP a Ã©tÃ© dÃ©compressÃ©
    And le paramÃ¨tre "delete_after_extract" est "true"
    When le nettoyage est exÃ©cutÃ©
    Then le fichier ZIP original doit Ãªtre supprimÃ©
    And les fichiers extraits doivent rester
```

---

### **6. `features/integration/autoloader.feature`**

```gherkin
# features/integration/autoloader.feature

Feature: Auto Loader Databricks
  Tester le chargement incrÃ©mental de fichiers

  Background:
    Given je suis sur Databricks
    And le checkpoint est dans "/Volumes/.../checkpoints/"

  @integration @autoloader
  Scenario: Charger des fichiers CSV avec Auto Loader
    Given des fichiers CSV existent dans "/Volumes/.../preprocessed/"
    When je dÃ©marre l'Auto Loader en mode "CSV"
    Then les fichiers doivent Ãªtre chargÃ©s
    And le checkpoint doit Ãªtre crÃ©Ã©
    And la colonne "FILE_NAME_RECEIVED" doit contenir les noms de fichiers

  @integration @autoloader
  Scenario: Charger des fichiers Parquet
    Given des fichiers Parquet existent dans "/Volumes/.../preprocessed/"
    When je dÃ©marre l'Auto Loader en mode "PARQUET"
    Then les fichiers doivent Ãªtre chargÃ©s
    And le schÃ©ma doit Ãªtre infÃ©rÃ© automatiquement

  @integration @autoloader
  Scenario: GÃ©rer l'arrivÃ©e de nouveaux fichiers
    Given l'Auto Loader est dÃ©jÃ  en cours
    And 5 fichiers ont Ã©tÃ© traitÃ©s
    When 3 nouveaux fichiers arrivent
    And je relance l'Auto Loader
    Then seuls les 3 nouveaux fichiers doivent Ãªtre traitÃ©s
    And le total de fichiers traitÃ©s doit Ãªtre 8
```

---

### **7. `features/integration/delta_operations.feature`**

```gherkin
# features/integration/delta_operations.feature

Feature: OpÃ©rations Delta Lake
  Tester les opÃ©rations sur les tables Delta

  Background:
    Given je suis sur Databricks
    And la table est "abu_catalog.gdp_poc_dev.site_clymene_all"

  @integration @delta
  Scenario: CrÃ©er une table Delta en mode FULL_SNAPSHOT
    Given le mode d'ingestion est "FULL_SNAPSHOT"
    And j'ai des donnÃ©es Ã  insÃ©rer
    When je crÃ©e la table Delta
    Then la table doit Ãªtre crÃ©Ã©e
    And les donnÃ©es doivent Ãªtre insÃ©rÃ©es
    And le nombre de lignes doit correspondre aux donnÃ©es sources

  @integration @delta
  Scenario: Mettre Ã  jour une table en mode MERGE
    Given la table Delta existe dÃ©jÃ 
    And le mode d'ingestion est "MERGE"
    And j'ai des donnÃ©es Ã  merger avec clÃ© "SITE_CODE"
    When j'exÃ©cute le merge
    Then les nouvelles lignes doivent Ãªtre insÃ©rÃ©es
    And les lignes existantes doivent Ãªtre mises Ã  jour
    And aucune ligne ne doit Ãªtre dupliquÃ©e

  @integration @delta
  Scenario: VÃ©rifier l'historique des versions Delta
    Given la table Delta a Ã©tÃ© modifiÃ©e 3 fois
    When je consulte l'historique
    Then je dois voir 3 versions
    And chaque version doit avoir un timestamp
    And je peux restaurer la version prÃ©cÃ©dente

  @integration @delta @negative
  Scenario: GÃ©rer une Ã©criture concurrente
    Given deux processus tentent d'Ã©crire simultanÃ©ment
    When les Ã©critures sont exÃ©cutÃ©es
    Then une seule doit rÃ©ussir
    Or un conflit doit Ãªtre dÃ©tectÃ© et rÃ©solu
```

---

### **8. `features/integration/column_processing.feature`**

```gherkin
# features/integration/column_processing.feature

Feature: Traitement des colonnes
  Tester les transformations de colonnes

  Background:
    Given je suis sur Databricks
    And j'ai un DataFrame avec des colonnes

  @integration @columns
  Scenario: Ajouter les colonnes systÃ¨me
    Given un DataFrame source
    When j'ajoute les colonnes systÃ¨me
    Then la colonne "FILE_NAME_RECEIVED" doit exister
    And la colonne "LOAD_DATE" doit exister
    And la colonne "LOAD_TIMESTAMP" doit avoir le timestamp actuel

  @integration @columns
  Scenario: Renommer les colonnes selon mapping
    Given un DataFrame avec colonnes:
      | old_name      | new_name       |
      | code_site     | SITE_CODE      |
      | libelle       | SITE_LIBELLE   |
      | date_creation | DATE_CREATION  |
    When j'applique le renommage
    Then les colonnes doivent Ãªtre renommÃ©es
    And "code_site" ne doit plus exister
    And "SITE_CODE" doit exister

  @integration @columns
  Scenario: Caster les types de colonnes
    Given un DataFrame avec colonne "MONTANT" de type STRING
    When je cast "MONTANT" en DOUBLE
    Then la colonne "MONTANT" doit Ãªtre de type DOUBLE
    And les valeurs doivent Ãªtre converties correctement
```

---

### **9. `features/integration/data_quality.feature`**

```gherkin
# features/integration/data_quality.feature

Feature: Validation qualitÃ© des donnÃ©es
  Tester les contrÃ´les qualitÃ©

  Background:
    Given je suis sur Databricks
    And j'ai configurÃ© les rÃ¨gles de qualitÃ©

  @integration @quality
  Scenario: Valider le nombre de lignes attendu
    Given le nombre de lignes attendu est 1000
    And la tolÃ©rance est "5%"
    When je charge 950 lignes
    Then la validation doit rÃ©ussir
    When je charge 800 lignes
    Then la validation doit Ã©chouer
    And une erreur doit Ãªtre enregistrÃ©e dans la table des erreurs

  @integration @quality
  Scenario: DÃ©tecter les valeurs NULL dans colonnes obligatoires
    Given la colonne "SITE_CODE" est obligatoire
    And j'ai un DataFrame avec 10 lignes
    And 2 lignes ont SITE_CODE = NULL
    When je valide les valeurs NULL
    Then la validation doit Ã©chouer
    And 2 erreurs doivent Ãªtre enregistrÃ©es

  @integration @quality
  Scenario: Valider les valeurs uniques
    Given la colonne "SITE_CODE" doit Ãªtre unique
    And j'ai un DataFrame avec 100 lignes
    And 5 valeurs sont dupliquÃ©es
    When je valide l'unicitÃ©
    Then la validation doit Ã©chouer
    And les doublons doivent Ãªtre listÃ©s

  @integration @quality
  Scenario: Valider les formats de donnÃ©es
    Given la colonne "EMAIL" doit respecter le format email
    And j'ai un DataFrame avec:
      | EMAIL                |
      | test@example.com     |
      | invalid-email        |
      | another@test.fr      |
    When je valide le format
    Then 1 erreur doit Ãªtre dÃ©tectÃ©e
    And "invalid-email" doit Ãªtre marquÃ© comme invalide
```

---

## ğŸ¯ **TESTS E2E (BOUT-EN-BOUT)**

### **10. `features/e2e/full_pipeline.feature`**

```gherkin
# features/e2e/full_pipeline.feature

Feature: Pipeline complet d'ingestion
  Tester le pipeline du dÃ©but Ã  la fin

  Background:
    Given je suis sur Databricks
    And les volumes sont configurÃ©s
    And la configuration est chargÃ©e

  @e2e @slow
  Scenario: Pipeline complet pour le dataset SITE
    # Ã‰tape 1 : Upload fichier
    Given un fichier ZIP "site_20251115_173355.zip" est uploadÃ© dans landing
    
    # Ã‰tape 2 : DÃ©compression
    When le module unzip est exÃ©cutÃ©
    Then le fichier doit Ãªtre dÃ©compressÃ© dans preprocessed
    
    # Ã‰tape 3 : Auto Loader
    When le module autoloader est exÃ©cutÃ©
    Then les donnÃ©es doivent Ãªtre chargÃ©es
    And le checkpoint doit Ãªtre crÃ©Ã©
    
    # Ã‰tape 4 : Traitement colonnes
    When le module column_processor est exÃ©cutÃ©
    Then les colonnes doivent Ãªtre transformÃ©es
    And les colonnes systÃ¨me doivent Ãªtre ajoutÃ©es
    
    # Ã‰tape 5 : Validation qualitÃ©
    When le module validator est exÃ©cutÃ©
    Then la qualitÃ© doit Ãªtre validÃ©e
    And aucune erreur critique ne doit Ãªtre dÃ©tectÃ©e
    
    # Ã‰tape 6 : Ã‰criture Delta
    When le module delta_manager est exÃ©cutÃ©
    Then les donnÃ©es doivent Ãªtre Ã©crites dans Delta
    And la table "site_clymene_all" doit exister
    
    # Ã‰tape 7 : Logging
    Then les logs doivent Ãªtre enregistrÃ©s dans "wax_execution_logs"
    And le statut doit Ãªtre "SUCCESS"

  @e2e @slow
  Scenario: Pipeline avec erreur de qualitÃ©
    Given un fichier avec donnÃ©es invalides
    When le pipeline est exÃ©cutÃ©
    Then la validation qualitÃ© doit Ã©chouer
    And les erreurs doivent Ãªtre dans "wax_data_quality_errors"
    And le statut final doit Ãªtre "FAILED_QUALITY"
    And aucune donnÃ©e ne doit Ãªtre Ã©crite en Delta
```

---

### **11. `features/e2e/orchestrator.feature`**

```gherkin
# features/e2e/orchestrator.feature

Feature: Orchestrateur de tests multi-datasets
  Tester plusieurs pipelines en parallÃ¨le

  Background:
    Given je suis sur Databricks
    And j'ai une baseline de rÃ©fÃ©rence

  @e2e @orchestrator
  Scenario: Orchestrer 3 pipelines en parallÃ¨le
    # Lancement des jobs
    When je lance le job "waxng_ingestion_site"
    And je lance le job "waxng_ingestion_activite"
    And je lance le job "waxng_ingestion_clymene"
    
    # Attente
    Then tous les jobs doivent se terminer en moins de 30 minutes
    And tous les jobs doivent rÃ©ussir
    
    # Collecte des rÃ©sultats
    When je collecte les outputs de tous les jobs
    Then chaque job doit avoir produit une table Delta
    And chaque table doit avoir des donnÃ©es
    
    # Validation globale
    When je valide contre la baseline
    Then le dataset "site" doit correspondre Ã  95%
    And le dataset "activite" doit correspondre Ã  98%
    And le dataset "clymene" doit correspondre Ã  99%
    
    # Rapport
    Then je gÃ©nÃ¨re un rapport consolidÃ©
    And le rapport doit contenir tous les datasets
    And le rapport doit afficher les mÃ©triques de qualitÃ©
```

---

### **12. `features/e2e/baseline_validation.feature`**

```gherkin
# features/e2e/baseline_validation.feature

Feature: Validation contre baseline
  Comparer les rÃ©sultats avec des donnÃ©es de rÃ©fÃ©rence

  Background:
    Given je suis sur Databricks
    And la baseline est chargÃ©e depuis "s3://baseline/wax/"

  @e2e @baseline
  Scenario Outline: Valider chaque dataset contre baseline
    Given le dataset "<dataset>" a Ã©tÃ© ingÃ©rÃ©
    When je charge les rÃ©sultats actuels
    And je charge la baseline
    Then le nombre de lignes doit correspondre Ã  <tolerance>%
    And les colonnes clÃ©s doivent correspondre Ã  100%
    And le nombre de NULL doit Ãªtre <= baseline
    And les valeurs dupliquÃ©es doivent Ãªtre <= baseline
    
    Examples:
      | dataset   | tolerance |
      | site      | 95        |
      | activite  | 98        |
      | clymene   | 99        |

  @e2e @baseline
  Scenario: DÃ©tecter une rÃ©gression qualitÃ©
    Given le dataset "site" avait 0 erreurs dans la baseline
    When le pipeline actuel produit 10 erreurs
    Then une rÃ©gression doit Ãªtre dÃ©tectÃ©e
    And une alerte doit Ãªtre levÃ©e
    And le rapport doit marquer le dataset comme "RÃ‰GRESSION"
```

---

## ğŸ”§ **IMPLÃ‰MENTATION DES STEPS**

Je continue avec les fichiers d'implÃ©mentation...

### **`features/steps/environment.py`**

```python
# features/steps/environment.py

"""Configuration Behave - DÃ©tection automatique du mode"""

import os
from pyspark.sql import SparkSession


def detect_test_mode(context):
    """DÃ©tecter le mode de test basÃ© sur les tags"""
    # Collecter tous les tags
    all_tags = set()
    for feature in context._runner.features:
        for scenario in feature.scenarios:
            all_tags.update(scenario.effective_tags)
    
    # DÃ©terminer le mode
    if 'integration' in all_tags or 'e2e' in all_tags:
        return 'integration'
    else:
        return 'unit'


def before_all(context):
    """Setup global"""
    print("\n" + "=" * 80)
    
    mode = detect_test_mode(context)
    context.test_mode = mode
    
    if mode == 'unit':
        print("ğŸ§ª MODE: TESTS UNITAIRES (sans Spark)")
        context.spark = None
        context.dbutils = None
    
    else:  # integration ou e2e
        print("ğŸš€ MODE: TESTS D'INTÃ‰GRATION (avec Databricks)")
        
        # Databricks
        if 'DATABRICKS_RUNTIME_VERSION' in os.environ:
            context.spark = SparkSession.getActiveSession()
            
            if context.spark is None:
                try:
                    import __main__
                    context.spark = __main__.spark
                except:
                    context.spark = SparkSession.builder.getOrCreate()
            
            try:
                from pyspark.dbutils import DBUtils
                context.dbutils = DBUtils(context.spark)
            except:
                context.dbutils = None
        
        # Local (dev)
        else:
            print("âš ï¸  ExÃ©cution locale - certains tests seront skippÃ©s")
            context.spark = None
            context.dbutils = None
    
    # Configuration
    context.catalog = "abu_catalog"
    context.schema = "gdp_poc_dev"
    context.volume = "externalvolumetest"
    
    print("=" * 80 + "\n")


def before_scenario(context, scenario):
    """Setup avant scÃ©nario"""
    print(f"\nğŸ“‹ {scenario.name}")
    print("-" * 80)
    
    # Reset variables
    context.current_df = None
    context.validation_errors = []
    context.job_runs = {}


def after_scenario(context, scenario):
    """Cleanup aprÃ¨s scÃ©nario"""
    status = "âœ… RÃ‰USSI" if scenario.status == "passed" else "âŒ Ã‰CHOUÃ‰"
    print(f"\n{status}")
    print("-" * 80)


def after_all(context):
    """Cleanup final"""
    print("\n" + "=" * 80)
    print("ğŸ TESTS TERMINÃ‰S")
    print("=" * 80)
```

---

Je vais maintenant crÃ©er les fichiers d'implÃ©mentation des steps...

### **`features/steps/unit_steps.py`**

```python
# features/steps/unit_steps.py

"""Steps pour tests unitaires (sans Spark)"""

from behave import given, when, then
import re
import json
from datetime import datetime


# ==========================================
# VALIDATION FICHIERS
# ==========================================

@given('un nom de fichier "{filename}"')
def step_given_filename(context, filename):
    context.filename = filename


@when('je valide le format du nom de fichier')
def step_validate_filename_format(context):
    pattern = r'^(site|activite|clymene)_(\d{8})_(\d{6})\.(csv|zip|parquet|json)$'
    context.is_valid = re.match(pattern, context.filename) is not None


@then('le rÃ©sultat doit Ãªtre {valid}')
def step_check_valid(context, valid):
    expected = valid.lower() == 'true'
    assert context.is_valid == expected


@when('j\'extrais la date et l\'heure')
def step_extract_datetime(context):
    pattern = r'^[^_]+_(\d{8})_(\d{6})\.'
    match = re.match(pattern, context.filename)
    
    if match:
        date_str = match.group(1)
        time_str = match.group(2)
        context.extracted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        context.extracted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"


@then('la date doit Ãªtre "{expected_date}"')
def step_check_date(context, expected_date):
    assert context.extracted_date == expected_date


@then('l\'heure doit Ãªtre "{expected_time}"')
def step_check_time(context, expected_time):
    assert context.extracted_time == expected_time


# ==========================================
# CONFIGURATION PARSING
# ==========================================

@given('un fichier de configuration JSON')
def step_given_json_config(context):
    context.json_config = context.text


@when('je parse la configuration')
def step_parse_config(context):
    try:
        context.parsed_config = json.loads(context.json_config)
        context.parse_error = None
    except json.JSONDecodeError as e:
        context.parsed_config = None
        context.parse_error = str(e)


@then('le dataset doit Ãªtre "{expected}"')
def step_check_dataset(context, expected):
    assert context.parsed_config['dataset'] == expected


@then('le mode doit Ãªtre "{expected}"')
def step_check_mode(context, expected):
    assert context.parsed_config['mode'] == expected


@then('une erreur doit Ãªtre levÃ©e')
def step_check_error_raised(context):
    assert context.parse_error is not None


@then('le message doit contenir "{text}"')
def step_check_error_message(context, text):
    assert text.lower() in str(context.parse_error).lower()


# ==========================================
# CALCUL TOLÃ‰RANCE
# ==========================================

@given('une tolÃ©rance de "{tolerance}"')
def step_given_tolerance(context, tolerance):
    context.tolerance_str = tolerance


@given('un total de {total:d} lignes')
def step_given_total(context, total):
    context.total = total


@when('je calcule la tolÃ©rance absolue')
def step_calculate_tolerance(context):
    try:
        tolerance_str = context.tolerance_str
        total = context.total
        
        if tolerance_str.endswith('%'):
            percentage = float(tolerance_str.rstrip('%'))
            context.tolerance_result = int(total * percentage / 100)
        else:
            context.tolerance_result = float(tolerance_str) / total
        
        context.tolerance_error = None
    except Exception as e:
        context.tolerance_error = e


@then('le rÃ©sultat doit Ãªtre {expected} lignes')
@then('le rÃ©sultat doit Ãªtre {expected}')
def step_check_tolerance_result(context, expected):
    expected_val = float(expected)
    assert context.tolerance_result == expected_val
```

---

### **`features/steps/integration_steps.py`**

```python
# features/steps/integration_steps.py

"""Steps pour tests d'intÃ©gration (avec Databricks)"""

from behave import given, when, then
import time


# ==========================================
# SETUP DATABRICKS
# ==========================================

@given('je suis sur Databricks')
def step_on_databricks(context):
    if context.test_mode == 'unit':
        context.scenario.skip("Test unitaire - Databricks non requis")
        return
    
    assert context.spark is not None, "Spark non disponible"
    print("âœ… Sur Databricks")


@given('le volume est "{volume}"')
def step_set_volume(context, volume):
    context.current_volume = volume


# ==========================================
# UNZIP
# ==========================================

@given('un fichier ZIP existe dans "{path}"')
def step_zip_exists(context, path):
    if context.dbutils is None:
        context.scenario.skip("dbutils requis")
        return
    
    try:
        context.dbutils.fs.ls(path)
        context.zip_path = path
        print(f"âœ… Fichier trouvÃ©: {path}")
    except:
        raise AssertionError(f"Fichier non trouvÃ©: {path}")


@when('je dÃ©compresse vers "{dest}"')
def step_unzip(context, dest):
    if context.dbutils is None:
        context.scenario.skip("dbutils requis")
        return
    
    try:
        context.dbutils.fs.unzip(context.zip_path, dest)
        context.extract_path = dest
        context.unzip_success = True
    except Exception as e:
        context.unzip_success = False
        context.unzip_error = e


@then('la dÃ©compression doit rÃ©ussir')
def step_verify_unzip_success(context):
    assert context.unzip_success


@then('au moins {count:d} fichier doit Ãªtre extrait')
def step_verify_file_count(context, count):
    if context.dbutils is None:
        return
    
    files = context.dbutils.fs.ls(context.extract_path)
    actual = len(files)
    assert actual >= count, f"Attendu >= {count}, trouvÃ© {actual}"


# ==========================================
# DELTA OPERATIONS
# ==========================================

@given('la table est "{table}"')
def step_set_table(context, table):
    context.current_table = table


@given('le mode d\'ingestion est "{mode}"')
def step_set_mode(context, mode):
    context.ingestion_mode = mode


@when('je crÃ©e la table Delta')
def step_create_delta_table(context):
    if context.spark is None:
        context.scenario.skip("Spark requis")
        return
    
    # Simulation - en vrai, appeleriez waxng.delta_manager
    context.table_created = True


@then('la table doit Ãªtre crÃ©Ã©e')
def step_verify_table_created(context):
    assert context.table_created


# ==========================================
# DATA QUALITY
# ==========================================

@given('j\'ai configurÃ© les rÃ¨gles de qualitÃ©')
def step_setup_quality_rules(context):
    context.quality_rules = {
        'expected_row_count': None,
        'tolerance': None,
        'mandatory_columns': []
    }


@given('le nombre de lignes attendu est {expected:d}')
def step_set_expected_rows(context, expected):
    context.quality_rules['expected_row_count'] = expected


@given('la tolÃ©rance est "{tolerance}"')
def step_set_tolerance(context, tolerance):
    context.quality_rules['tolerance'] = tolerance


@when('je charge {count:d} lignes')
def step_load_rows(context, count):
    context.actual_row_count = count
    
    # Calculer si dans tolÃ©rance
    expected = context.quality_rules['expected_row_count']
    tolerance_str = context.quality_rules['tolerance']
    
    tolerance_pct = float(tolerance_str.rstrip('%'))
    tolerance_abs = int(expected * tolerance_pct / 100)
    
    context.validation_passed = (
        abs(count - expected) <= tolerance_abs
    )


@then('la validation doit rÃ©ussir')
def step_validation_success(context):
    assert context.validation_passed


@then('la validation doit Ã©chouer')
def step_validation_fail(context):
    assert not context.validation_passed
```

---

### **`features/steps/e2e_steps.py`**

```python
# features/steps/e2e_steps.py

"""Steps pour tests E2E"""

from behave import given, when, then
import time


# ==========================================
# ORCHESTRATION
# ==========================================

@given('j\'ai une baseline de rÃ©fÃ©rence')
def step_load_baseline(context):
    context.baseline = {
        'site': {'row_count': 1000, 'quality_score': 0.95},
        'activite': {'row_count': 5000, 'quality_score': 0.98},
        'clymene': {'row_count': 2000, 'quality_score': 0.99}
    }


@when('je lance le job "{job_name}"')
def step_launch_job(context, job_name):
    if context.dbutils is None:
        # Simulation
        context.job_runs[job_name] = {
            'status': 'RUNNING',
            'start_time': time.time()
        }
        return
    
    # Code rÃ©el Databricks
    from databricks.sdk import WorkspaceClient
    w = WorkspaceClient()
    
    jobs = list(w.jobs.list(name=job_name))
    if not jobs:
        raise AssertionError(f"Job non trouvÃ©: {job_name}")
    
    run = w.jobs.run_now(job_id=jobs[0].job_id)
    context.job_runs[job_name] = {
        'run_id': run.run_id,
        'status': 'RUNNING'
    }


@then('tous les jobs doivent se terminer en moins de {minutes:d} minutes')
def step_wait_jobs(context, minutes):
    max_wait = minutes * 60
    start = time.time()
    
    while time.time() - start < max_wait:
        all_done = all(
            run['status'] in ['SUCCESS', 'FAILED']
            for run in context.job_runs.values()
        )
        
        if all_done:
            return
        
        time.sleep(30)
    
    raise AssertionError(f"Timeout aprÃ¨s {minutes} minutes")


@then('tous les jobs doivent rÃ©ussir')
def step_all_jobs_success(context):
    for job_name, run in context.job_runs.items():
        # Simulation
        run['status'] = 'SUCCESS'
        
        assert run['status'] == 'SUCCESS', \
            f"Job Ã©chouÃ©: {job_name}"


@when('je collecte les outputs de tous les jobs')
def step_collect_outputs(context):
    context.outputs = {}
    for job_name in context.job_runs.keys():
        dataset = job_name.split('_')[-1]
        context.outputs[dataset] = {
            'table': f"{context.catalog}.{context.schema}.{dataset}_all",
            'row_count': 1000  # Simulation
        }


@when('je valide contre la baseline')
def step_validate_baseline(context):
    context.baseline_results = {}
    
    for dataset, output in context.outputs.items():
        if dataset not in context.baseline:
            continue
        
        baseline = context.baseline[dataset]
        actual = output['row_count']
        expected = baseline['row_count']
        
        match_pct = (actual / expected) if expected > 0 else 0
        
        context.baseline_results[dataset] = {
            'match_percentage': match_pct
        }


@then('le dataset "{dataset}" doit correspondre Ã  {percentage:d}%')
def step_check_baseline_match(context, dataset, percentage):
    result = context.baseline_results[dataset]
    actual_pct = result['match_percentage'] * 100
    
    assert actual_pct >= percentage, \
        f"{dataset}: {actual_pct}% < {percentage}%"


@then('je gÃ©nÃ¨re un rapport consolidÃ©')
def step_generate_report(context):
    context.report = {
        'jobs': len(context.job_runs),
        'datasets': len(context.outputs),
        'baseline_checks': len(context.baseline_results)
    }
    print(f"âœ… Rapport: {context.report}")
```

---

## ğŸ“Š **NOTEBOOKS D'EXÃ‰CUTION**

### **`notebooks/run_unit_tests.py`**

```python
# Databricks notebook source

# MAGIC %md
# MAGIC # ğŸ§ª Tests Unitaires WAX NG

# COMMAND ----------

%pip install behave>=1.2.6 --quiet

# COMMAND ----------

import subprocess
import sys
from pathlib import Path

# Trouver features
import waxng
features_path = Path(waxng.__file__).parent.parent / "features" / "unit"

print(f"ğŸ“‚ Features: {features_path}")

# ExÃ©cuter tests unitaires
result = subprocess.run([
    sys.executable, "-m", "behave",
    str(features_path),
    "--format", "pretty",
    "--tags", "unit"
])

if result.returncode != 0:
    raise Exception("Tests Ã©chouÃ©s")
```

---

### **`notebooks/run_integration_tests.py`**

```python
# Databricks notebook source

# MAGIC %md
# MAGIC # ğŸš€ Tests d'IntÃ©gration WAX NG

# COMMAND ----------

%pip install behave>=1.2.6 --quiet
dbutils.library.restartPython()

# COMMAND ----------

import subprocess
import sys
from pathlib import Path

import waxng
features_path = Path(waxng.__file__).parent.parent / "features" / "integration"

result = subprocess.run([
    sys.executable, "-m", "behave",
    str(features_path),
    "--format", "pretty",
    "--tags", "integration"
])

if result.returncode != 0:
    raise Exception("Tests Ã©chouÃ©s")
```

---

### **`notebooks/run_e2e_tests.py`**

```python
# Databricks notebook source

# MAGIC %md
# MAGIC # ğŸ¯ Tests E2E WAX NG

# COMMAND ----------

%pip install behave>=1.2.6 databricks-sdk --quiet
dbutils.library.restartPython()

# COMMAND ----------

import subprocess
import sys
from pathlib import Path

import waxng
features_path = Path(waxng.__file__).parent.parent / "features" / "e2e"

result = subprocess.run([
    sys.executable, "-m", "behave",
    str(features_path),
    "--format", "pretty",
    "--tags", "e2e"
])

if result.returncode != 0:
    raise Exception("Tests Ã©chouÃ©s")
```

---

## ğŸš€ **DÃ‰PLOIEMENT**

```bash
# 1. CrÃ©er tous les fichiers
mkdir -p features/{unit,integration,e2e,steps}
mkdir -p notebooks
mkdir -p baseline

# 2. Builder le wheel
python setup.py bdist_wheel

# 3. DÃ©ployer
databricks bundle deploy --target dev

# 4. Lancer les tests
databricks jobs run-now --job-name "waxng_unit_tests"
databricks jobs run-now --job-name "waxng_integration_tests"
databricks jobs run-now --job-name "waxng_e2e_tests"
```

---

**Vous avez maintenant une suite COMPLÃˆTE de tests BDD pour votre projet ! ğŸ¯**

**Cette suite couvre :**
- âœ… Tests unitaires (rapides, sans Spark)
- âœ… Tests d'intÃ©gration (avec Databricks)
- âœ… Tests E2E (orchestration complÃ¨te)
- âœ… Validation baseline
- âœ… 12 features avec 50+ scÃ©narios

**PrÃªt Ã  tester ! ğŸš€**
